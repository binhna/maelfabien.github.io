---
published: true
title: Speaker Verification using Gaussian Mixture Model (GMM-UBM)
collection: ml
layout: single
author_profile: false
read_time: true
categories: [machinelearning]
excerpt : "Speech Processing"
header :
    overlay_image: "https://maelfabien.github.io/assets/images/lgen_head.png"
    teaser : "https://maelfabien.github.io/assets/images/wolf.jpg"
comments : true
toc: true
toc_sticky: true
sidebar:
    nav: sidebar-sample
---

<script type="text/javascript" async
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

The methods introduced below are called GMM-UBM, which stands for Gaussian Mixture Model - Universal Background Model. 

### Speech acquisition

Speech acquisition is done through Voice Activity Detection (VAD). A common approach is the Gaussian-based VAD. The aim of a VAD is to aquire speech only when it occurs.

The main steps behin building a VAD are:
- Break audio signal into frames
- Extract features from each frame
- Train a classifier on a known set of speech and silence frames
- Classify unseen frames as speech or silence

But this will be the topic of another article. VAD performs well on audio with relatively low signal-to-noice ratio (SNR), a ratio which compares the level of a desired signal to the level of background noise.

### Feature extraction

Once we can efficiently acquire a speech signal, we should extract features from the signal to convert the raw signal into a sequence of acoustic feature vectures which we will use to identify the speaker. 

A common choice for the features to extract from the signal is the Mel Frequency Cepstral Coefficients (MFCC). These features are derivedd from Fast Fourier Transform. There are several steps and options for extracting MFCC features, both in time and frequency domains, but again, I'll dive deeper into this topic in another article.

### Universal Background Model : Development

The next step, once we extracted the features, is to train a universal background model (UBM). We train such algorithm because there is typically not enough data available to train the speaker models.

A UBM is a high-order Gaussian Mixture Model trained on a large quantity of speech, from a wide population. This step is used to learn speaker-independent distribution of features.

### Speaker Enrolment

The last step before the verification is to perform the speaker enrolement. The aim is still to train a Gaussian Mixture Model on the extracted features. GMMs are typically solved iteratively by an Expectation Maximization (EM) algorithm, an algorithm which tries to maximize the likelihood of the training data by adjusting the parameters of the GMM.

The issue is always to initialize the parameters of the GMM the right way. Since we pre-trained a GMM in the development step, we simply start the EM algorithm with the parameters learned by the UBM.

Through this step, we only adapt the mean, and not the covariance, since updating the covariance does not improve the performance.

For the mean to update, we perform a *maximum a posteriori adaptation* :

$$ \mu_k^{MAP} = \alpha_k \mu_k + (1 - \alpha_k) \mu_k^{UBM} $$

Where :
- $ \alpha_k = \frac{n_k}{n_k + \tau_k} $ is the mean adaptation coefficient
- $ n_k $ is the count for the adaptation data
- $ \tau_k $ is the relevance factor, between 8 and 32

### Speaker Verification

The Speaker Verification is finally computed using the likelihood ratio, since GMM is a generative model.

We test the following underlying hypothesis:
- $ H_0 $ : Sample X belongs to claimed speaker s
- $ H_1 $ : Sample X does not belong to claimedd speaker s

The likelihood ratio is then defined as :

$$ S(X) = \frac{P(X \mid H_0)} {P(X \mid H_1)} $$

We compare this ratio to a threshold, and if it is greater than the defined threshold, we accept that the sample X belongs to the claimed speaker s.

# Limits of GMM-UBM

Nowadays, GMM-UBM are not state-of-the-art approaches anymore. Indeed, it requires too much training data in general. Better performing approaches have been developed such as :
- SVM-based methods
- I-vector methods
- Deep-learning based methods


